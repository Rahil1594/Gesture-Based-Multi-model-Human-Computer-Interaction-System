![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/483eec01-d78a-4207-a9cf-cd2e00dbcb0a)<h1 align="center" style="border-bottom: none">
    <b>
        <a href="https://www.google.com">Gesture Based Multi-model Human-Computer Interaction System </a><br>
    </b>
    ⭐️ Human-Computer Interaction ⭐️ <br>
</h1>



This project highlights the real-time nature of the project, showcasing various HCI innovations such as virtual mouse control, volume adjustment through hand gestures, eye-controlled mouse functionality, and real-time photo capture. It conveys the dynamic and interactive nature of your code.


:point_right:OBJECTIVE : To develop an accurate and responsive hand-controlled mouse interface using computer vision to provide users with a natural, hands-free interaction method that enhances accessibility, productivity, and creativity in digital environments in a different ways.



![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/02d5df8c-e6b5-46ce-90af-5e0bf7f5602b)



![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/57699240-c421-4524-80ef-6fb2781f18ba)

## Team Details
`Team number` : VH109

| Name              | Email                 |
|-------------------|-----------------------|
| S.Md.Rahil Azam   | 9921004705@klu.ac.in  |
| M.Mujeeb          | 9921004468@klu.ac.in  |
| S.Mohaseen Sameer | 99210041637@klu.ac.in |
| Venkat Shiva      | 99210041@klu.ac.in    |






<div
alt="Image 2" style="width: 30%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/9b438930-5b48-4a2d-abdb-e40850a122bd" alt="Image 2" style="width: 30%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/74db2919-bc4b-4b04-bace-b3670bad306c" alt="Image 3" style="width: 30%; margin: 5px;">
    <img src="(https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/f1eecdbf-babf-4068-b047-62077bdbbf9e" 
</div>




:point_right:PROBLEM STATEMENT : Develop a graphical user interface (GUI) application that uses computer vision techniques to enable various interactions with the computer, including hand gesture-based volume control, virtual mouse control using hand movements, eye-controlled mouse movement and clicking, and capturing and displaying images from the webcam.


## About the project

The system increases accessibility and user experience greatly by allowing people to control and interact with computers through gestures, thus providing an alternative to traditional input devices. It also has the potential to empower people with motor disabilities by giving them more independence and access to digital resources.  


## Technical implemntaion 
mention the approach and how you have solved the problem with the technology , utilize multiple flowcharts to explain your solutions and approach

- be consise and specific
- explain with images and flowcharts
- 
![flowchart](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSm5X9E8h0kftXOW2B9jORBskdXF12pFKOX_Q&usqp=CAU)

## Techstacks used 
'PY3' 

## How to run locally 
steps to run the project:
1. checkout/download repository code.
2. install all dependecies--> pip install - required libraries as in code.
3. Run Code Especially in "IDLE PYTHON MODULE".

# What's next ?
The future plan for the project is to make it accurate and efficient by using advanced processors,by allowing smooth accessability for the user.

## Declaration
We confirm that the project showcased here was either developed entirely during the hackathon or underwent significant updates within the hackathon timeframe. We understand that if any plagiarism from online sources is detected, our project will be disqualified, and our participation in the hackathon will be revoked.

> [!NOTE]
> Useful information that users should know, even when skimming content.

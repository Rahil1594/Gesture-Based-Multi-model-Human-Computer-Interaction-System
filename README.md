![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/483eec01-d78a-4207-a9cf-cd2e00dbcb0a)<h1 align="center" style="border-bottom: none">
    <b>
        <a href="https://www.google.com">Gesture Based Multi-model Human-Computer Interaction System </a><br>
    </b>
   ⭐ Human-Computer Interaction ⭐<br>
</h1>

# [`Demo video link `](https://www.youtube.com/watch?v=FJETuAvrsys&t=19s)

This project highlights the real-time nature of the project, showcasing various HCI innovations such as virtual mouse control, volume adjustment through hand gestures, eye-controlled mouse functionality, and real-time photo capture. It conveys the dynamic and interactive nature of your code.




:point_right:OBJECTIVE : To develop an accurate and responsive hand-controlled mouse interface using computer vision to provide users with a natural, hands-free interaction method that enhances accessibility, productivity, and creativity in digital environments in a different ways.



## Team Details
`Team number` : VH109

| Name              | Email                 |
|-------------------|-----------------------|
| S.Md.Rahil Azam   | 9921004705@klu.ac.in  |
| M.Mujeeb          | 9921004468@klu.ac.in  |
| S.Mohaseen Sameer | 99210041637@klu.ac.in |
| Venkat Shiva      | 99210041504@klu.ac.in |



![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System-VH109-/assets/158186032/91368b80-73a2-4f3a-8cd6-3c7ac7d9d8b7)



<div
alt="Image 2" style="width: 30%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/9b438930-5b48-4a2d-abdb-e40850a122bd" alt="Image 2" style="width: 30%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/74db2919-bc4b-4b04-bace-b3670bad306c" 
        alt="Image 3" style="width: 30%; margin: 5px;">
    <img src="(![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System-VH109-/assets/158186032/1e984140-6167-437a-8b9f-170764196909)
" 
</div>






:point_right:PROBLEM STATEMENT : Develop a graphical user interface (GUI) application that uses computer vision techniques to enable various interactions with the computer, including hand gesture-based volume control, virtual mouse control using hand movements, eye-controlled mouse movement and clicking, and capturing and displaying images from the webcam.


## About the project

The system increases accessibility and user experience greatly by allowing people to control and interact with computers through gestures, thus providing an alternative to traditional input devices. It also has the potential to empower people with motor disabilities by giving them more independence and access to digital resources.  



## Technical implemntaion 
mention the approach and how you have solved the problem with the technology , utilize multiple flowcharts to explain your solutions and approach

- We have used OpenCV for Camera Calibration and 3D Reconstruction.
- And then the algorithm converts one color space into RGB to BGR.
- By using the camera , the algorithm uses some pakages to detect Hand Gestures for the further functioning.
- After that PyatoGUI contols the increase or decrease in the volume.
- Use your thumb and index finger to use this function.
- Similarly,for the virtual mouse a user can move the pointer by using hand gestures.
![flowchart](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System-VH109-/assets/158186032/72bdc8f4-d0d5-4fcb-9ace-f6e0694d4334)




## Techstacks used 
'PY3' ,'OpenCV'

## How to run locally 
steps to run the project:
1. clone the repository.
2. install all dependecies--> pip install -r requirement.txt.
3. Run Code Especially in "IDLE PYTHON MODULE".
4. Wait for the camera to open.
5. Show your hand to camera to use mouse pointer or to use other functionalities.


# What's next ?
The future plan for the project is to make it accurate and efficient by using advanced processors,by allowing smooth accessability for the user.



## Declaration
We confirm that the project showcased here was either developed entirely during the hackathon or underwent significant updates within the hackathon timeframe. We understand that if any plagiarism from online sources is detected, our project will be disqualified, and our participation in the hackathon will be revoked.





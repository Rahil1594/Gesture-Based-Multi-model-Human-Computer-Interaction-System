![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/483eec01-d78a-4207-a9cf-cd2e00dbcb0a)<h1 align="center" style="border-bottom: none">
    <b>
        <a href="https://www.google.com">Gesture Based Multi-model Human-Computer Interaction System </a><br>
    </b>
   ‚≠ê Human-Computer Interaction ‚≠ê<br>
</h1>

# [`Demo video link `](https://www.youtube.com/watch?v=FJETuAvrsys&t=19s)

It highlights the real-time nature of the project, showcasing various HCI innovations such as virtual mouse control, volume adjustment through hand gestures, eye-controlled mouse functionality, and real-time photo capture. It conveys the dynamic and interactive nature of code.




:point_right:OBJECTIVE : To develop an accurate and responsive hand-controlled mouse interface using computer vision to provide users with a natural, hands-free interaction method that enhances accessibility, productivity, and creativity in digital environments in a different ways.



## Team Details
`Team number` : VH109

| Name              | Email                 |
|-------------------|-----------------------|
| S.Md.Rahil Azam   | 9921004705@klu.ac.in  |
| M.Mujeeb          | 9921004468@klu.ac.in  |
| S.Mohaseen Sameer | 99210041637@klu.ac.in |
| A.Venkat Shiva    | 99210041504@klu.ac.in |





<div
alt="Image 1" style="width: 10%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/9b438930-5b48-4a2d-abdb-e40850a122bd"
alt="Image 2" style="width: 30%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System-VH109-/assets/158186032/91368b80-73a2-4f3a-8cd6-3c7ac7d9d8b7"
 alt="Image 3" style="width: 30%; margin: 5px;">
    <img src="https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System/assets/158186032/74db2919-bc4b-4b04-bace-b3670bad306c" 
</div>




## :point_right:Problem Statement
Develop a graphical user interface (GUI) application that uses computer vision techniques to enable various interactions with the computer, including hand gesture-based volume control, virtual mouse control using hand movements, eye-controlled mouse movement and clicking, and capturing and displaying images from the webcam.


## About the project

The system increases accessibility and user experience greatly by allowing people to control and interact with computers through gestures, thus providing an alternative to traditional input devices. It also has the potential to empower people with motor disabilities by giving them more independence and access to digital resources.  



## Technical implementation 

- We have used OpenCV for Camera Calibration and 3D Reconstruction.
- And then the algorithm converts one color space into RGB to BGR.
- By using OpenCV for camera, the PyautoGUI helps to detect Hand Gestures for the further functioning.
- By action with fingers PyatoGUI contols the increase or decrease in the volume.
- Use your thumb and index finger to use this function.
- Similarly,for the virtual mouse a user can move the pointer by using hand gestures.

![image](https://github.com/Rahil1594/Gesture-Based-Multi-model-Human-Computer-Interaction-System-VH109-/assets/158186032/bab1e2bc-f70c-46b1-9de0-fa302ce49f69)



## Techstacks used 
'PY3' , 'OpenCV'


## How to run locally 
### steps to run the project:
1. clone the repository.
2. install all dependecies--> pip install -r requirements.txt.
3. Run Code Especially in "IDLE PYTHON MODULE".
4. Select required button from Dialogue Box.
5. And Wait for the camera to open.
6. Show your hand infront of camera to use mouse pointer or to use other functionalities.


# üìå NOTE : The accuracy and performance of the algorithm depends on the System Processesor and GPU.
   
            

## What's next ?
The future plan for the project is to make it accurate and efficient by using advanced processors,by allowing smooth accessability for the user.



## Declaration
We confirm that the project showcased here was either developed entirely during the hackathon or underwent significant updates within the hackathon timeframe. We understand that if any plagiarism from online sources is detected, our project will be disqualified, and our participation in the hackathon will be revoked.




